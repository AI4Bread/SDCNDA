from sklearn.preprocessing import label_binarize
from torch_geometric.data import Data
import torch_geometric.transforms as T
import scipy.io
import csv
import pandas as pd
import json
from os import path
import os
import torch
import torch.nn.functional as F
import numpy as np
from scipy import sparse as sp
from model import *

def rand_train_test_idx(label, train_prop, valid_prop, test_prop, ignore_negative=True):
    """ randomly splits label into train/valid/test splits """
    labeled_nodes = torch.where(label != -1)[0]

    n = labeled_nodes.shape[0]
    train_num = int(n * train_prop)
    valid_num = int(n * valid_prop)
    test_num = int(n * test_prop)

    perm = torch.as_tensor(np.random.permutation(n))

    train_indices = perm[:train_num]
    val_indices = perm[train_num:train_num + valid_num]
    test_indices = perm[train_num + valid_num:train_num + valid_num + test_num]

    train_idx = train_indices
    valid_idx = val_indices
    test_idx = test_indices

    return {'train': train_idx.numpy(), 'valid': valid_idx.numpy(), 'test': test_idx.numpy()}

def index_to_mask(splits_lst, num_nodes):
    mask_len = len(splits_lst)
    train_mask = torch.zeros((mask_len, num_nodes), dtype=torch.bool)
    val_mask = torch.zeros((mask_len, num_nodes), dtype=torch.bool)
    test_mask = torch.zeros((mask_len, num_nodes), dtype=torch.bool)

    for i in range(mask_len):
        train_mask[i][splits_lst[i]['train']] = True
        val_mask[i][splits_lst[i]['valid']] = True
        test_mask[i][splits_lst[i]['test']] = True

    return train_mask.T, val_mask.T, test_mask.T

from typing import Optional, Callable
import os.path as osp
import torch
import numpy as np
from torch_geometric.utils import to_undirected
from torch_geometric.data import InMemoryDataset, download_url, Data

# import gdown
def load_dataset(dataname, train_prop, valid_prop, test_prop, num_masks):
    #666
    assert dataname in ('ncrna_disease'), 'Invalid dataset'
    if dataname == 'ncrna_disease':
        data = load_ncrna_disease_dataset('dataset1/data/data1.1', 0.6, 0.2, 0.2, 5)
    else:
        data = load_dataset(dataname, 0.6, 0.2, 0.2, 5)
    return data

import torch
import numpy as np
from torch_geometric.data import Data
from load_data import rand_train_test_idx, index_to_mask

def load_ncrna_disease_dataset(dataset_name='data1.1', train_prop=0.6, valid_prop=0.2, test_prop=0.2, num_masks=5):

    import os
    
    data_dir = f'../data/{dataset_name}/'
    
    print(f"Loading {dataset_name} dataset from {data_dir}")
    
    # åŠ è½½é‚»æ¥çŸ©é˜µ A
    A_path = os.path.join(data_dir, 'matrix_A.npy')
    if not os.path.exists(A_path):
        raise FileNotFoundError(f"matrix_A.npy not found at {A_path}")
    matrix_A = np.load(A_path)
    print(f"âœ… Loaded matrix_A: {matrix_A.shape}")
    
    # åŠ è½½æ ‡å‡†åŒ–åçš„ç‰¹å¾çŸ©é˜µ (ç”¨ä½œèŠ‚ç‚¹ç‰¹å¾)
    feature_path = os.path.join(data_dir, 'feature.pt')
    if not os.path.exists(feature_path):
        raise FileNotFoundError(f"feature.pt not found at {feature_path}")
    features = torch.load(feature_path)
    print(f"âœ… Loaded features: {features.shape}")
    
    # åŠ è½½èŠ‚ç‚¹æ ‡ç­¾
    label_path = os.path.join(data_dir, 'label.pt')
    if not os.path.exists(label_path):
        raise FileNotFoundError(f"label.pt not found at {label_path}")
    labels = torch.load(label_path)  
    print(f"âœ… Loaded labels: {labels.shape}")
    
    # ğŸ”¥ ç›´æ¥ä» labels ç”Ÿæˆ type_vecï¼ˆlabels å°±æ˜¯èŠ‚ç‚¹ç±»å‹ï¼ï¼‰
    type_vec = labels.cpu().numpy() if isinstance(labels, torch.Tensor) else labels.copy()
    print(f"âœ… Generated type_vec from labels: {type_vec.shape}")
    print(f"ğŸ“Š Node types: lncRNA={np.sum(type_vec==0)}, disease={np.sum(type_vec==1)}, miRNA={np.sum(type_vec==2)}")
    
    # ä» matrix_A æ„é€ è¾¹ä¿¡æ¯
    def construct_edge_indices_from_A(A, type_vec):
        """ä»é‚»æ¥çŸ©é˜µAå’Œtype_vecæ„é€ åŒå±‚è¾¹å’Œè·¨å±‚è¾¹"""
        # è·å–éé›¶è¾¹
        row, col = np.where(A > 0)
        edge_index_full = torch.tensor([row, col], dtype=torch.long)
        
        if len(row) == 0:
            print("âš ï¸ Warning: No edges found in matrix_A")
            # è¿”å›ç©ºçš„è¾¹ç´¢å¼•
            edge_index_same = torch.zeros((2, 0), dtype=torch.long)
            edge_index_cross = torch.zeros((2, 0), dtype=torch.long)
            return edge_index_same, edge_index_cross, edge_index_full
        
        type_vec_tensor = torch.tensor(type_vec, dtype=torch.long)
        
        # è·å–æ¯æ¡è¾¹ä¸¤ç«¯èŠ‚ç‚¹çš„ç±»å‹
        row_types = type_vec_tensor[edge_index_full[0]]
        col_types = type_vec_tensor[edge_index_full[1]]
        
        # åŒå±‚è¾¹ï¼šä¸¤ç«¯èŠ‚ç‚¹ç±»å‹ç›¸åŒ (è¯­ä¹‰è§†è§’)
        same_type_mask = (row_types == col_types)
        # è·¨å±‚è¾¹ï¼šä¸¤ç«¯èŠ‚ç‚¹ç±»å‹ä¸åŒ (ç»“æ„è§†è§’)
        cross_type_mask = ~same_type_mask
        
        edge_index_same = edge_index_full[:, same_type_mask]   # åŒå±‚è¾¹ï¼ˆè¯­ä¹‰ï¼‰
        edge_index_cross = edge_index_full[:, cross_type_mask] # è·¨å±‚è¾¹ï¼ˆç»“æ„ï¼‰
        
        print(f"ğŸ“Š Edge statistics:")
        print(f"   - Total edges: {edge_index_full.shape[1]}")
        print(f"   - Same-type edges (semantic): {edge_index_same.shape[1]}")
        print(f"   - Cross-type edges (structure): {edge_index_cross.shape[1]}")
        
        return edge_index_same, edge_index_cross, edge_index_full
    
    # æ„é€ è¾¹ç´¢å¼•
    edge_index_same, edge_index_cross, edge_index_full = construct_edge_indices_from_A(matrix_A, type_vec)
    
    # ç”Ÿæˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†
    splits_lst = [rand_train_test_idx(labels, train_prop=train_prop, valid_prop=valid_prop, test_prop=test_prop)
                  for _ in range(num_masks)]
    train_mask, val_mask, test_mask = index_to_mask(splits_lst, len(labels))
    
    # åˆ›å»º Data å¯¹è±¡
    data = Data(
        x=features,                    # èŠ‚ç‚¹ç‰¹å¾ (å½’ä¸€åŒ–åçš„AçŸ©é˜µ)
        edge_index=edge_index_full,    # å®Œæ•´çš„è¾¹ç´¢å¼•
        y=labels,                      # èŠ‚ç‚¹æ ‡ç­¾
        train_mask=train_mask,
        val_mask=val_mask, 
        test_mask=test_mask,
        num_nodes=len(labels)
    )
    
    # æ·»åŠ é¢å¤–çš„è¾¹ä¿¡æ¯ (ä¾› S3GCL ä½¿ç”¨)
    data.edge_index_same = edge_index_same     # åŒå±‚è¾¹ (è¯­ä¹‰è§†è§’)
    data.edge_index_cross = edge_index_cross   # è·¨å±‚è¾¹ (ç»“æ„è§†è§’)
    data.type_vec = torch.tensor(type_vec, dtype=torch.long)  # èŠ‚ç‚¹ç±»å‹ (å°±æ˜¯labelsçš„å‰¯æœ¬)
    data.matrix_A = torch.tensor(matrix_A, dtype=torch.float)  # åŸå§‹é‚»æ¥çŸ©é˜µ
    
    print(f"ğŸ‰ Successfully loaded {dataset_name}:")
    print(f"   - Nodes: {data.num_nodes}")
    print(f"   - Features: {data.x.shape[1]}")
    print(f"   - Classes: {len(torch.unique(labels))}")
    print(f"   - Node types: lncRNA={torch.sum(data.type_vec==0)}, disease={torch.sum(data.type_vec==1)}, miRNA={torch.sum(data.type_vec==2)}")
    
    return data